{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.AI Text Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**currently there is no tool are platform that can directly generate a 10-15 min video by the user input, so until then ignore the first step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Function to generate a video based on user input\n",
    "def generate_video():\n",
    "    # Take the topic as input from the user\n",
    "    topic = input(\"Enter the topic for video generation: \")\n",
    "    \n",
    "    # Assuming you have the correct Gemini AI API endpoint and access token\n",
    "    url = \"https://api.gemini.ai/video/generate\"  # Replace with the correct API endpoint\n",
    "    headers = {\"Authorization\": \"Bearer AIzaSyCGpope1kq4V_pFtnvDGhNbpZdWYwU81bg\"}  # Replace with your actual access token\n",
    "    data = {\"topic\": topic}\n",
    "    \n",
    "    # Send a POST request to the API with the user input topic\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    \n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Return the video URL if successful\n",
    "        video_url = response.json().get('video_url')\n",
    "        if video_url:\n",
    "            print(f\"Video generated successfully! You can view it here: {video_url}\")\n",
    "        else:\n",
    "            print(\"Video generation failed: No video URL returned.\")\n",
    "    else:\n",
    "        # Print error message if the API call fails\n",
    "        print(f\"Video generation failed with status code: {response.status_code}\")\n",
    "\n",
    "# Call the function to generate a video\n",
    "generate_video()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"EleutherAI/gpt-neo-2.7B\"  # Using GPT-Neo model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Define the topic based on user input\n",
    "topic = input(\"Enter the topic: \")\n",
    "\n",
    "# Prompt to generate content about the topic\n",
    "content_prompt = f\"Explain the concept of {topic}: \"\n",
    "\n",
    "# Tokenize the input for content generation\n",
    "content_input_ids = tokenizer.encode(content_prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate the content\n",
    "content_output = model.generate(\n",
    "    content_input_ids,\n",
    "    max_length=200,  # Adjust the length according to your needs\n",
    "    temperature=0.7,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    no_repeat_ngram_size=2,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode the generated content\n",
    "generated_content = tokenizer.decode(content_output[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated content\n",
    "print(\"\\nGenerated Content:\")\n",
    "print(generated_content)\n",
    "\n",
    "# Prompt to generate assignment questions based on the content\n",
    "question_prompt = f\"Generate a  5 assignment questions  ,like creative and innovative about {topic}: \"\n",
    "\n",
    "# Tokenize the input for question generation\n",
    "question_input_ids = tokenizer.encode(question_prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate the questions\n",
    "question_output = model.generate(\n",
    "    question_input_ids,\n",
    "    max_length=100,  # Adjust the length according to your needs\n",
    "    temperature=0.7,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    no_repeat_ngram_size=2,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode the generated questions\n",
    "generated_questions = tokenizer.decode(question_output[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated questions\n",
    "print(\"\\nGenerated Assignment Questions:\")\n",
    "print(generated_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def test_api():\n",
    "    url = \"https://jsonplaceholder.typicode.com/posts\"  # Public API for testing\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"API is reachable!\")\n",
    "        print(response.json())  # Print the JSON response from the test API\n",
    "    else:\n",
    "        print(f\"Failed to reach API with status code: {response.status_code}\")\n",
    "\n",
    "# Call the test function\n",
    "test_api()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.**Text Summarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "def summarize_text(video_transcript):\n",
    "    response = openai.Completion.create(\n",
    "      model=\"gpt-4\",\n",
    "      prompt=f\"Summarize the following text: {video_transcript}\",\n",
    "      temperature=0.5,\n",
    "      max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.Assingnment Question Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(summary):\n",
    "    response = openai.Completion.create(\n",
    "      model=\"gpt-4\",\n",
    "      prompt=f\"Generate assignment questions based on the following summary: {summary}\",\n",
    "      temperature=0.5,\n",
    "      max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.Score prediction(ML)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample Data (you would need a dataset of user answers and corresponding scores)\n",
    "X = user_answers_data  # Features: e.g., user answers\n",
    "y = scores_data        # Labels: e.g., user scores\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Random Forest Classifier for Score Prediction\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the score\n",
    "def predict_score(user_input):\n",
    "    return model.predict([user_input])\n",
    "\n",
    "# Example usage:\n",
    "predicted_score = predict_score(user_input_data)\n",
    "print(f\"Predicted Score: {predicted_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.Identifying strong and week topics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_performance(predicted_score, threshold=0.75):\n",
    "    if predicted_score >= threshold:\n",
    "        return \"Strong in the topic\"\n",
    "    else:\n",
    "        return \"Weak in the topic\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.Generate video solution on weeker topics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_video_solution(weak_topic):\n",
    "    # Re-use the video generation API with a different prompt\n",
    "    return generate_video(weak_topic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.Monitoring student progress and guiding individually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_and_guide(user_data):\n",
    "    # This function can track behavior, progress, and give personalized suggestions.\n",
    "    if user_data['communication'] < threshold:\n",
    "        return \"Work on communication skills.\"\n",
    "    if user_data['discipline'] < threshold:\n",
    "        return \"Focus on discipline and values.\"\n",
    "    # Additional personalized guidance logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
